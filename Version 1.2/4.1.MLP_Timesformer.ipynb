{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4f1f5f-d455-42fb-8225-4a87fc325e42",
   "metadata": {},
   "source": [
    "# MLP sobre embeddings CLS (TimeSformer Frozen)\n",
    "\n",
    "Este notebook entrena un clasificador MLP binario usando embeddings CLS precomputados de TimeSformer.\n",
    "Entrada: archivos `.mmap` en `processed/`.\n",
    "Salida: métricas (AUC, F1, Recall, FAR) y artefactos de resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbaa326-eb01-4ff1-ac5e-e5a8324cdb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "PROCESSED = Path(\"processed\")\n",
    "MANIFEST_PATH = PROCESSED / \"manifest_timesformer_cls.json\"\n",
    "assert MANIFEST_PATH.exists(), f\"No existe {MANIFEST_PATH}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb9f47-f02a-45a7-974b-de553325e9b2",
   "metadata": {},
   "source": [
    "### Paso X — Carga del *manifest* y apertura de embeddings con `memmap` (train/val/test)\n",
    "\n",
    "Esta celda **carga el archivo `manifest.json`** del experimento y luego **abre (sin cargar a RAM)** los archivos binarios (`.bin`/`.dat`) que contienen:\n",
    "\n",
    "- `y_train`, `y_val`, `y_test`: etiquetas (0/1) guardadas como vector 1D (`int8`).\n",
    "- `X_train`, `X_val`, `X_test`: embeddings del codificador guardados como matriz 2D (`float16`) de forma `(N, D)`.\n",
    "\n",
    "La idea central es usar **`np.memmap`** para trabajar con datasets grandes: se mapean desde disco y se leen “on demand”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28141346-61c3-46f0-a1fc-9375bbb7ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: facebook/timesformer-base-finetuned-k400\n",
      "T: 8 IMG_SIZE: 224 D: 768\n",
      "N_train, N_val, N_test: 106527 19793 19036\n",
      "X_train shape: (106527, 768) dtype: float16\n"
     ]
    }
   ],
   "source": [
    "with open(MANIFEST_PATH, \"r\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "print(\"Model:\", manifest[\"model\"])\n",
    "print(\"T:\", manifest[\"T\"], \"IMG_SIZE:\", manifest[\"img_size\"], \"D:\", manifest[\"embedding_dim\"])\n",
    "\n",
    "files = manifest[\"files\"]\n",
    "\n",
    "D = int(manifest[\"embedding_dim\"])\n",
    "\n",
    "def infer_1d_length(file_path: Path, dtype: str) -> int:\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    assert nbytes % item == 0, \"Tamaño de archivo no calza con dtype\"\n",
    "    return nbytes // item\n",
    "\n",
    "def open_y(file_path: Path, dtype=\"int8\"):\n",
    "    N = infer_1d_length(file_path, dtype)\n",
    "    y = np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N,))\n",
    "    return y\n",
    "\n",
    "def open_X(file_path: Path, N: int, D: int, dtype=\"float16\"):\n",
    "    # Validar que el tamaño calza con N*D\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    expected = N * D * item\n",
    "    assert nbytes == expected, f\"X size mismatch. got={nbytes}, expected={expected}\"\n",
    "    X = np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N, D))\n",
    "    return X\n",
    "\n",
    "# Abrir y primero (para inferir N)\n",
    "y_train = open_y(Path(files[\"y_train\"]), dtype=\"int8\")\n",
    "y_val   = open_y(Path(files[\"y_val\"]), dtype=\"int8\")\n",
    "y_test  = open_y(Path(files[\"y_test\"]), dtype=\"int8\")\n",
    "\n",
    "\n",
    "N_train, N_val, N_test = len(y_train), len(y_val), len(y_test)\n",
    "print(\"N_train, N_val, N_test:\", N_train, N_val, N_test)\n",
    "\n",
    "# Abrir X con shapes correctas\n",
    "X_train = open_X(Path(files[\"X_train\"]), N_train, D, dtype=\"float16\")\n",
    "X_val   = open_X(Path(files[\"X_val\"]),   N_val,   D, dtype=\"float16\")\n",
    "X_test  = open_X(Path(files[\"X_test\"]),  N_test,  D, dtype=\"float16\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"dtype:\", X_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374e968d-92d7-448b-a89c-b9c0f54e70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: {'X_train': 'processed/emb_timesformer_cls_train.mmap', 'y_train': 'processed/y_train.mmap', 'X_val': 'processed/emb_timesformer_cls_val.mmap', 'y_val': 'processed/y_val.mmap', 'X_test': 'processed/emb_timesformer_cls_test.mmap', 'y_test': 'processed/y_test.mmap'}\n",
      "y_train mean: 0.4930017741980906\n",
      "y_val mean: 0.45839438185216996\n",
      "y_test mean: 0.5198045807942845\n",
      "train counts: [54009 52518]\n",
      "val counts: [10720  9073]\n",
      "test counts: [9141 9895]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"files:\", manifest[\"files\"])\n",
    "\n",
    "print(\"y_train mean:\", float(np.mean(y_train)))\n",
    "print(\"y_val mean:\", float(np.mean(y_val)))\n",
    "print(\"y_test mean:\", float(np.mean(y_test)))\n",
    "\n",
    "# también cuenta clases\n",
    "print(\"train counts:\", np.bincount(np.array(y_train, dtype=np.int64)))\n",
    "print(\"val counts:\",   np.bincount(np.array(y_val, dtype=np.int64)))\n",
    "print(\"test counts:\",  np.bincount(np.array(y_test, dtype=np.int64)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04e1f2-65aa-4fa2-a2df-ee45fcf405e5",
   "metadata": {},
   "source": [
    "### Paso X — Construcción del `Dataset` y `DataLoader` para embeddings (PyTorch)\n",
    "\n",
    "#### ¿Qué se hace en esta celda?\n",
    "Esta celda define un `Dataset` personalizado que envuelve los `memmap` (`X_*`, `y_*`) y luego crea los `DataLoader` de **train / val / test** para alimentar el MLP.\n",
    "\n",
    "Aquí se pasa de:\n",
    "- Datos almacenados en disco (`np.memmap`)\n",
    "a\n",
    "- Tensores PyTorch listos para entrenamiento por batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e788227-b771-4fd9-80e7-681fc9a211c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders ready.\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X_mm, y_mm):\n",
    "        self.X = X_mm\n",
    "        self.y = y_mm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = np.array(self.X[i], dtype=np.float32)\n",
    "        y = float(self.y[i])\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(EmbeddingDataset(X_train, y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "val_loader   = DataLoader(EmbeddingDataset(X_val, y_val),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader  = DataLoader(EmbeddingDataset(X_test, y_test),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Loaders ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12ed08-2155-4001-a1c0-b09130e13bb7",
   "metadata": {},
   "source": [
    "### Paso X — Definición del clasificador MLP y configuración de entrenamiento\n",
    "\n",
    "Aquí se define el **clasificador supervisado** que opera sobre los embeddings `(N, D)` generados por el encoder.  \n",
    "El encoder ya está congelado; este MLP aprende a mapear cada embedding → probabilidad de anomalía.\n",
    "\n",
    "Se configuran además:\n",
    "- función de pérdida,\n",
    "- optimizador,\n",
    "- y se instancia el modelo en el dispositivo (`CPU` o `GPU`).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1918df40-9317-431f-9865-ae3b4c63b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DIINF/dvaldes/venvs/tesis/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=768):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = MLP(in_dim=D).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de77185-f65b-4bc0-b22c-e99fec644efb",
   "metadata": {},
   "source": [
    "### Paso X — Función de evaluación (`eval_loader`)\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    " Se define `eval_loader(...)`, una función que:\n",
    "- ejecuta el modelo en modo evaluación sobre un `DataLoader`,\n",
    "- obtiene probabilidades,\n",
    "- calcula métricas (AUC, F1, Recall, FAR),\n",
    "- y devuelve además los vectores `(y, p)` para análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afe1a4c3-0a11-4787-aa40-3a60a674c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loader(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            logits = model(xb)\n",
    "            prob = torch.sigmoid(logits)\n",
    "\n",
    "            ys.append(yb.detach().cpu().numpy())\n",
    "            ps.append(prob.detach().cpu().numpy())\n",
    "\n",
    "    y = np.concatenate(ys)\n",
    "    p = np.concatenate(ps)\n",
    "\n",
    "    auc = roc_auc_score(y, p)\n",
    "    yhat = (p >= threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y, yhat)\n",
    "    rec = recall_score(y, yhat)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "    far = fp / (fp + tn + 1e-9)\n",
    "\n",
    "    return {\"auc\": auc, \"f1\": f1, \"recall\": rec, \"far\": far}, (y, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90896d-c293-44f5-9635-3e8bca13b08a",
   "metadata": {},
   "source": [
    "### Paso X — loop de entrenamiento con *early stopping*\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    "\n",
    "Se ejecuta el entrenamiento por épocas:\n",
    "- forward → loss → backward → update,\n",
    "- evaluación en validación por época,\n",
    "- *early stopping* basado en **val AUC**,\n",
    "- y finalmente se restaura el mejor modelo (según AUC de validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb8e076-12bd-4cf8-ac5c-3e2e9e368dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.0474 | val_auc=0.9458 val_f1=0.8748 val_recall=0.8709 val_far=0.1018\n",
      "Epoch 02 | train_loss=0.0028 | val_auc=0.9306 val_f1=0.8552 val_recall=0.8736 val_far=0.1434\n",
      "Epoch 03 | train_loss=0.0017 | val_auc=0.9446 val_f1=0.8585 val_recall=0.8380 val_far=0.0967\n",
      "Epoch 04 | train_loss=0.0014 | val_auc=0.9271 val_f1=0.8150 val_recall=0.9126 val_far=0.2768\n",
      "Early stopping.\n",
      "Best val AUC: 0.9457588151083006\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "PATIENCE = 3\n",
    "\n",
    "best_auc = -1.0\n",
    "best_state = None\n",
    "bad = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss.detach().cpu().item()))\n",
    "\n",
    "    train_loss = sum(losses) / max(1, len(losses))\n",
    "    val_metrics, _ = eval_loader(model, val_loader, threshold=0.5)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | \"\n",
    "          f\"val_auc={val_metrics['auc']:.4f} val_f1={val_metrics['f1']:.4f} \"\n",
    "          f\"val_recall={val_metrics['recall']:.4f} val_far={val_metrics['far']:.4f}\")\n",
    "\n",
    "    if val_metrics[\"auc\"] > best_auc + 1e-4:\n",
    "        best_auc = val_metrics[\"auc\"]\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Restaurar mejor modelo\n",
    "assert best_state is not None\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Best val AUC:\", best_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1a473-65c1-40c6-93e4-fb6dfa327157",
   "metadata": {},
   "source": [
    "## Paso 1 — Evaluación de desempeño (Validation y Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se evalúa el clasificador MLP sobre los splits **val** y **test** usando `eval_loader`, obteniendo:\n",
    "- métricas principales (AUC, F1, Recall, FAR)\n",
    "- los vectores `(y, p)` para análisis posterior (ROC y matriz de confusión).\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión de métricas por split\n",
    "- Variables listas: `val_metrics`, `test_metrics`, `y_val_np`, `p_val_np`, `y_test_np`, `p_test_np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7036872-57db-4698-81a8-018c1aad4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: {'auc': 0.9457588151083006, 'f1': 0.8747924277648622, 'recall': 0.8709357434145266, 'far': np.float64(0.10177238805969199)}\n",
      "TEST: {'auc': 0.9225873089604727, 'f1': 0.85284618490109, 'recall': 0.853966649823143, 'far': np.float64(0.16092331254784367)}\n"
     ]
    }
   ],
   "source": [
    "val_metrics, (y_val_np, p_val_np) = eval_loader(model, val_loader, threshold=0.5)\n",
    "test_metrics, (y_test_np, p_test_np) = eval_loader(model, test_loader, threshold=0.5)\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3410538-38ac-42b4-a773-aa4c132b4086",
   "metadata": {},
   "source": [
    "## Paso 2 — Matriz de confusión (Test) + métrica de Accuracy\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se fija un umbral (`0.5`) para convertir probabilidades en clases 0/1, y se calcula:\n",
    "- `Accuracy`\n",
    "- Matriz de confusión: TN, FP, FN, TP\n",
    "\n",
    "### Resultado esperado\n",
    "- Matriz de confusión (tabla 2×2)\n",
    "- Valores TN/FP/FN/TP impresos\n",
    "- Accuracy impresa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58216e66-0a9d-4c7e-a655-440662f52825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion Matrix (TEST) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7670</td>\n",
       "      <td>1471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1445</td>\n",
       "      <td>8450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0    7670    1471\n",
       "Actual 1    1445    8450"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN=7670 FP=1471 FN=1445 TP=8450\n",
      "Accuracy (TEST) = 0.8468\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.5\n",
    "y_test_bin = (p_test_np >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_np, y_test_bin)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc_test = accuracy_score(y_test_np, y_test_bin)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (TEST) ===\")\n",
    "display(cm_df)\n",
    "print(f\"TN={tn} FP={fp} FN={fn} TP={tp}\")\n",
    "print(f\"Accuracy (TEST) = {acc_test:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f986491-acdd-4c13-85fb-c0ae89d4e722",
   "metadata": {},
   "source": [
    "## Paso 3 — Curva ROC (Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se construye y grafica la curva ROC con:\n",
    "- FPR (False Positive Rate)\n",
    "- TPR (True Positive Rate)\n",
    "\n",
    "### Resultado esperado\n",
    "- Gráfico ROC del split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06a108da-9243-4335-9a08-487bd9d0f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_np, p_test_np)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC - TimeSformer (CLS) + MLP (TEST)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c2fa8-d005-4b5a-a313-b3154df60e53",
   "metadata": {},
   "source": [
    "## Paso 4 — Tabla resumen de desempeño (Validation vs Test) y guardado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se genera una tabla final con métricas de desempeño (val/test) y se guarda en CSV.\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `results_df`\n",
    "- Archivo CSV exportado a `processed/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70789050-60c6-4344-83f4-50a0b1101f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados de Desempeño: TimeSformer (CLS) + MLP ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FAR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Validation</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>0.8709</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.8468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Split     AUC      F1  Recall     FAR  Accuracy\n",
       "0  Validation  0.9458  0.8748  0.8709  0.1018    0.8857\n",
       "1        Test  0.9226  0.8528  0.8540  0.1609    0.8468"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/results_performance_timesformer_mlp.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Split\": [\"Validation\", \"Test\"],\n",
    "    \"AUC\": [val_metrics[\"auc\"], test_metrics[\"auc\"]],\n",
    "    \"F1\": [val_metrics[\"f1\"], test_metrics[\"f1\"]],\n",
    "    \"Recall\": [val_metrics[\"recall\"], test_metrics[\"recall\"]],\n",
    "    \"FAR\": [val_metrics[\"far\"], test_metrics[\"far\"]],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_val_np, (p_val_np >= threshold).astype(int)),\n",
    "        accuracy_score(y_test_np, (p_test_np >= threshold).astype(int)),\n",
    "    ],\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n=== Resultados de Desempeño: TimeSformer (CLS) + MLP ===\\n\")\n",
    "display(results_df)\n",
    "\n",
    "out_csv = PROCESSED / \"results_performance_timesformer_mlp.csv\"\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de694c0f-224f-4fba-9d8d-37dde1a64a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def uniform_sample_indices(start_f: int, end_f: int, T: int):\n",
    "    n = max(1, end_f - start_f)\n",
    "    idx = np.linspace(0, n - 1, T).round().astype(int)\n",
    "    return (start_f + idx).astype(int)\n",
    "\n",
    "class ClipDataset(Dataset):\n",
    "    def __init__(self, df, T=8, img_size=224):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.T = T\n",
    "        self.img_size = img_size\n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "        self.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"path\"]\n",
    "        start_f = int(row[\"start_frame\"])\n",
    "        end_f   = int(row[\"end_frame\"])\n",
    "        y = int(row[\"y\"])\n",
    "\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(f\"No pude abrir video: {path}\")\n",
    "\n",
    "        frame_ids = uniform_sample_indices(start_f, end_f, self.T)\n",
    "\n",
    "        frames = []\n",
    "        last_good = None\n",
    "        for fid in frame_ids:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))\n",
    "            ok, frame = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                frame = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8) if last_good is None else last_good\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "                last_good = frame\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        arr = np.stack(frames).astype(np.float32) / 255.0\n",
    "        arr = (arr - self.mean) / self.std\n",
    "        arr = np.transpose(arr, (3, 0, 1, 2))  # (C,T,H,W)\n",
    "        clip = torch.from_numpy(arr)\n",
    "\n",
    "        return clip, torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51a66a-f949-4f30-8ae5-21f8ab3d317a",
   "metadata": {},
   "source": [
    "## Paso 5 — Métricas operativas del encoder (latencia, ms/frame, FPS)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se mide el tiempo de inferencia del encoder TimeSformer sobre batches reales:\n",
    "- warmup (no medir los primeros batches)\n",
    "- medición promedio por batch\n",
    "- latencia por clip\n",
    "- ms/frame\n",
    "- FPS efectivo\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión: avg s/batch, ms/clip, ms/frame, FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "875045e6-f9af-48ad-a693-ef4a8811b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 5: Métricas Operativas (Encoder TimeSformer) ===\n",
      "Checkpoint: facebook/timesformer-base-finetuned-k400\n",
      "T: 8 IMG_SIZE: 224\n",
      "DEVICE: cuda\n",
      "\n",
      "Batches medidos: 200\n",
      "Batch size: 8\n",
      "Tiempo promedio por batch: 0.3390 s\n",
      "Latencia por clip: 42.37 ms/clip\n",
      "Tiempo por frame: 5.30 ms/frame\n",
      "FPS efectivo: 188.80 fps\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 5 — Métricas operativas del encoder (latencia, ms/frame, FPS)\n",
    "# =========================\n",
    "# Este Notebook (04) entrena un MLP sobre embeddings, así que aquí volvemos\n",
    "# a cargar el encoder TimeSformer SOLO para medir latencia y FLOPs.\n",
    "#\n",
    "# Nota metodológica:\n",
    "# - Esto mide desempeño del ENCODER (forward) con input sintético (tensor dummy),\n",
    "#   lo cual es reproducible y evita depender de loaders de video.\n",
    "# - Si quieres medir con clips reales, te dejo más abajo la variante opcional.\n",
    "\n",
    "import time\n",
    "import torch\n",
    "from transformers import TimesformerModel\n",
    "\n",
    "# 1) Variables desde el manifest (ya las imprimiste arriba)\n",
    "T = int(manifest[\"T\"])\n",
    "IMG_SIZE = int(manifest[\"img_size\"])\n",
    "\n",
    "# 2) Checkpoint del encoder (idealmente debe coincidir con el de extracción)\n",
    "#    Si en tu manifest guardaste el nombre, úsalo. Si no, fallback:\n",
    "TIMESFORMER_CKPT = manifest.get(\"model\", \"facebook/timesformer-base-finetuned-k400\")\n",
    "\n",
    "print(\"\\n=== Paso 5: Métricas Operativas (Encoder TimeSformer) ===\")\n",
    "print(\"Checkpoint:\", TIMESFORMER_CKPT)\n",
    "print(\"T:\", T, \"IMG_SIZE:\", IMG_SIZE)\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# 3) Cargar encoder\n",
    "encoder = TimesformerModel.from_pretrained(TIMESFORMER_CKPT).to(DEVICE)\n",
    "encoder.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_encoder_latency(\n",
    "    encoder,\n",
    "    T: int,\n",
    "    img_size: int,\n",
    "    device: str,\n",
    "    batch_size: int = 8,\n",
    "    n_batches: int = 200,\n",
    "    warmup: int = 10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Mide latencia del forward del encoder con input dummy.\n",
    "    Retorna:\n",
    "      - time_per_batch_s\n",
    "      - time_per_clip_s\n",
    "      - time_per_frame_s\n",
    "      - fps_effective\n",
    "    \"\"\"\n",
    "    # input dummy (B, T, C, H, W) tal como lo espera HF TimeSformer\n",
    "    dummy = torch.randn(batch_size, T, 3, img_size, img_size, device=device)\n",
    "\n",
    "    # Warmup (evita medir batches lentos iniciales)\n",
    "    for _ in range(warmup):\n",
    "        _ = encoder(pixel_values=dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(n_batches):\n",
    "        _ = encoder(pixel_values=dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    time_per_batch_s = elapsed / n_batches\n",
    "    time_per_clip_s  = time_per_batch_s / batch_size\n",
    "    time_per_frame_s = time_per_clip_s / T\n",
    "    fps_effective    = 1.0 / time_per_frame_s  # frames/s\n",
    "\n",
    "    return {\n",
    "        \"batches_measured\": int(n_batches),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"T\": int(T),\n",
    "        \"img_size\": int(img_size),\n",
    "        \"time_per_batch_s\": float(time_per_batch_s),\n",
    "        \"time_per_clip_s\": float(time_per_clip_s),\n",
    "        \"time_per_frame_s\": float(time_per_frame_s),\n",
    "        \"fps_effective\": float(fps_effective),\n",
    "    }\n",
    "\n",
    "# 4) Ejecutar medición\n",
    "op = measure_encoder_latency(\n",
    "    encoder=encoder,\n",
    "    T=T,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    batch_size=8,     # ajusta según VRAM\n",
    "    n_batches=200,\n",
    "    warmup=10,\n",
    ")\n",
    "\n",
    "time_per_clip  = op[\"time_per_clip_s\"]\n",
    "time_per_frame = op[\"time_per_frame_s\"]\n",
    "fps_effective  = op[\"fps_effective\"]\n",
    "\n",
    "print(\"\\nBatches medidos:\", op[\"batches_measured\"])\n",
    "print(\"Batch size:\", op[\"batch_size\"])\n",
    "print(f\"Tiempo promedio por batch: {op['time_per_batch_s']:.4f} s\")\n",
    "print(f\"Latencia por clip: {time_per_clip*1000:.2f} ms/clip\")\n",
    "print(f\"Tiempo por frame: {time_per_frame*1000:.2f} ms/frame\")\n",
    "print(f\"FPS efectivo: {fps_effective:.2f} fps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713a841-343a-4c67-8c9b-045fd7ad4386",
   "metadata": {},
   "source": [
    "## Paso 6 — Time-To-Alert (TTA) estimado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima un **time-to-alert** aproximado como:\n",
    "- duración temporal de la ventana (clip) = `T / fps_video`\n",
    "- + latencia computacional (ms/clip)\n",
    "\n",
    "### Resultado esperado\n",
    "- Duración ventana\n",
    "- Latencia computacional\n",
    "- TTA estimado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf85616f-cb20-4794-b0a4-041b8d6b73e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 6: Time-To-Alert (TTA) ===\n",
      "FPS video asumido: 30\n",
      "Duración ventana (clip): 0.267 s\n",
      "Latencia computacional: 0.042 s\n",
      "Time-To-Alert estimado: 0.309 s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 6 — Time-To-Alert (TTA) estimado\n",
    "# =========================\n",
    "# Requiere: T, time_per_clip (calculado en Paso 5)\n",
    "video_fps = 30  # ajusta si tu fuente es distinta\n",
    "\n",
    "latencia_clip_ms = time_per_clip * 1000.0\n",
    "duracion_clip_s = T / video_fps\n",
    "tta_s = duracion_clip_s + (latencia_clip_ms / 1000.0)\n",
    "\n",
    "print(\"\\n=== Paso 6: Time-To-Alert (TTA) ===\")\n",
    "print(f\"FPS video asumido: {video_fps}\")\n",
    "print(f\"Duración ventana (clip): {duracion_clip_s:.3f} s\")\n",
    "print(f\"Latencia computacional: {latencia_clip_ms/1000:.3f} s\")\n",
    "print(f\"Time-To-Alert estimado: {tta_s:.3f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33515a13-2293-400a-9613-f7e5b9bba057",
   "metadata": {},
   "source": [
    "## Paso 7 — Complejidad computacional (FLOPs y parámetros)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima:\n",
    "- GFLOPs del encoder\n",
    "- número de parámetros\n",
    "\n",
    "Usando `thop` sobre un tensor dummy con forma compatible.\n",
    "\n",
    "### Resultado esperado\n",
    "- GFLOPs\n",
    "- Params (millones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84dbf875-35a6-45d1-bd1c-51a6028f0fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 7: Complejidad Computacional ===\n",
      "FLOPs: 190.05 GFLOPs\n",
      "Parámetros: 121.10 M\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 7 — Complejidad computacional (GFLOPs y parámetros)\n",
    "# =========================\n",
    "# Requiere: encoder, DEVICE, T, IMG_SIZE\n",
    "# Nota: el input dummy se arma en formato (B, T, C, H, W) para HF TimeSformer\n",
    "\n",
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "dummy = torch.randn(1, T, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "# THOP usa inputs posicionales; para HF a veces requiere keyword.\n",
    "# Si profile falla, usa el wrapper simple de abajo.\n",
    "try:\n",
    "    flops, params = profile(encoder, inputs=(dummy,), verbose=False)\n",
    "except Exception:\n",
    "    class EncoderWrapper(torch.nn.Module):\n",
    "        def __init__(self, enc):\n",
    "            super().__init__()\n",
    "            self.enc = enc\n",
    "        def forward(self, x):\n",
    "            out = self.enc(pixel_values=x)\n",
    "            # devolver algo tensorial para THOP (si devuelve objeto con last_hidden_state)\n",
    "            if hasattr(out, \"last_hidden_state\"):\n",
    "                return out.last_hidden_state\n",
    "            if isinstance(out, (tuple, list)):\n",
    "                return out[0]\n",
    "            return out\n",
    "\n",
    "    wrapped = EncoderWrapper(encoder).to(DEVICE)\n",
    "    flops, params = profile(wrapped, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(\"\\n=== Paso 7: Complejidad Computacional ===\")\n",
    "print(f\"FLOPs: {flops/1e9:.2f} GFLOPs\")\n",
    "print(f\"Parámetros: {params/1e6:.2f} M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c48383-a294-4ce4-9354-75f484ea1b53",
   "metadata": {},
   "source": [
    "## Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se arma una tabla única para reportar en tesis, combinando:\n",
    "- desempeño (Test)\n",
    "- métricas operativas (ms/frame, FPS, TTA)\n",
    "- costo computacional (GFLOPs)\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `final_table`\n",
    "- CSV exportado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15d9d5cc-3b83-423a-9b93-f3ee633b3824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>FAR (Test)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>ms/frame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>TTA (s)</th>\n",
       "      <th>GFLOPs</th>\n",
       "      <th>Params (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TimeSformer + MLP</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.1609</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>7670</td>\n",
       "      <td>1471</td>\n",
       "      <td>1445</td>\n",
       "      <td>8450</td>\n",
       "      <td>5.3</td>\n",
       "      <td>188.8</td>\n",
       "      <td>0.309</td>\n",
       "      <td>190.05</td>\n",
       "      <td>121.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Modelo  AUC (Test)  F1 (Test)  Recall (Test)  FAR (Test)  \\\n",
       "0  TimeSformer + MLP      0.9226     0.8528          0.854      0.1609   \n",
       "\n",
       "   Accuracy (Test)    TN    FP    FN    TP  ms/frame    FPS  TTA (s)  GFLOPs  \\\n",
       "0           0.8468  7670  1471  1445  8450       5.3  188.8    0.309  190.05   \n",
       "\n",
       "   Params (M)  \n",
       "0       121.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/final_report_timesformer_full.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "# =========================\n",
    "# Requiere: test_metrics, acc_test, tn, fp, fn, tp, flops, params, tta_s,\n",
    "#           time_per_frame, fps_effective, y objeto Path/dir PROCESSED (o usa string)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajusta esta ruta si tu proyecto usa otra variable (PROCESSED_DIR, etc.)\n",
    "PROCESSED = Path(\"processed\")\n",
    "\n",
    "final_table = pd.DataFrame({\n",
    "    \"Modelo\": [\"TimeSformer + MLP\"],\n",
    "    \"AUC (Test)\": [round(test_metrics[\"auc\"], 4)],\n",
    "    \"F1 (Test)\": [round(test_metrics[\"f1\"], 4)],\n",
    "    \"Recall (Test)\": [round(test_metrics[\"recall\"], 4)],\n",
    "    \"FAR (Test)\": [round(test_metrics[\"far\"], 4)],\n",
    "    \"Accuracy (Test)\": [round(float(acc_test), 4)],\n",
    "    \"TN\": [int(tn)], \"FP\": [int(fp)], \"FN\": [int(fn)], \"TP\": [int(tp)],\n",
    "    \"ms/frame\": [round(time_per_frame * 1000.0, 2)],\n",
    "    \"FPS\": [round(float(fps_effective), 2)],\n",
    "    \"TTA (s)\": [round(float(tta_s), 3)],\n",
    "    \"GFLOPs\": [round(float(flops/1e9), 2)],\n",
    "    \"Params (M)\": [round(float(params/1e6), 2)],\n",
    "})\n",
    "\n",
    "display(final_table)\n",
    "\n",
    "out_csv = PROCESSED / \"final_report_timesformer_full.csv\"\n",
    "final_table.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e2aa0-86fb-49d3-85f3-501c4ad90558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
