{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4f1f5f-d455-42fb-8225-4a87fc325e42",
   "metadata": {},
   "source": [
    "# MLP sobre embeddings CLS (TimeSformer Frozen)\n",
    "\n",
    "Este notebook entrena un clasificador MLP binario usando embeddings CLS precomputados de TimeSformer.\n",
    "Entrada: archivos `.mmap` en `processed/`.\n",
    "Salida: métricas (AUC, F1, Recall, FAR) y artefactos de resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fbaa326-eb01-4ff1-ac5e-e5a8324cdb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "PROCESSED = Path(\"processed\")\n",
    "MANIFEST_PATH = PROCESSED / \"manifest_swin3d_t.json\"\n",
    "\n",
    "assert MANIFEST_PATH.exists(), f\"No existe {MANIFEST_PATH}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb9f47-f02a-45a7-974b-de553325e9b2",
   "metadata": {},
   "source": [
    "### Paso X — Carga del *manifest* y apertura de embeddings con `memmap` (train/val/test)\n",
    "\n",
    "Esta celda **carga el archivo `manifest.json`** del experimento y luego **abre (sin cargar a RAM)** los archivos binarios (`.bin`/`.dat`) que contienen:\n",
    "\n",
    "- `y_train`, `y_val`, `y_test`: etiquetas (0/1) guardadas como vector 1D (`int8`).\n",
    "- `X_train`, `X_val`, `X_test`: embeddings del codificador guardados como matriz 2D (`float16`) de forma `(N, D)`.\n",
    "\n",
    "La idea central es usar **`np.memmap`** para trabajar con datasets grandes: se mapean desde disco y se leen “on demand”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28141346-61c3-46f0-a1fc-9375bbb7ab73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T: 8 IMG_SIZE: 224 D: 768\n",
      "N_train, N_val, N_test: 106527 19793 19036\n",
      "X_train shape: (106527, 768) dtype: float16\n"
     ]
    }
   ],
   "source": [
    "with open(MANIFEST_PATH, \"r\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "\n",
    "print(\"T:\", manifest[\"T\"], \"IMG_SIZE:\", manifest[\"img_size\"], \"D:\", manifest[\"embedding_dim\"])\n",
    "\n",
    "files = manifest[\"files\"]\n",
    "\n",
    "D = int(manifest[\"embedding_dim\"])\n",
    "\n",
    "def infer_1d_length(file_path: Path, dtype: str) -> int:\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    assert nbytes % item == 0, \"Tamaño de archivo no calza con dtype\"\n",
    "    return nbytes // item\n",
    "\n",
    "def open_y(file_path: Path, dtype=\"int8\"):\n",
    "    N = infer_1d_length(file_path, dtype)\n",
    "    y = np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N,))\n",
    "    return y\n",
    "\n",
    "def open_X(file_path: Path, N: int, D: int, dtype=\"float16\"):\n",
    "    # Validar que el tamaño calza con N*D\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    expected = N * D * item\n",
    "    assert nbytes == expected, f\"X size mismatch. got={nbytes}, expected={expected}\"\n",
    "    X = np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N, D))\n",
    "    return X\n",
    "\n",
    "# Abrir y primero (para inferir N)\n",
    "y_train = open_y(Path(files[\"y_train\"]), dtype=\"int8\")\n",
    "y_val   = open_y(Path(files[\"y_val\"]), dtype=\"int8\")\n",
    "y_test  = open_y(Path(files[\"y_test\"]), dtype=\"int8\")\n",
    "\n",
    "\n",
    "N_train, N_val, N_test = len(y_train), len(y_val), len(y_test)\n",
    "print(\"N_train, N_val, N_test:\", N_train, N_val, N_test)\n",
    "\n",
    "# Abrir X con shapes correctas\n",
    "X_train = open_X(Path(files[\"X_train\"]), N_train, D, dtype=\"float16\")\n",
    "X_val   = open_X(Path(files[\"X_val\"]),   N_val,   D, dtype=\"float16\")\n",
    "X_test  = open_X(Path(files[\"X_test\"]),  N_test,  D, dtype=\"float16\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"dtype:\", X_train.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374e968d-92d7-448b-a89c-b9c0f54e70a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files: {'X_train': 'processed/emb_swin3d_t_train.mmap', 'y_train': 'processed/y_train.mmap', 'X_val': 'processed/emb_swin3d_t_val.mmap', 'y_val': 'processed/y_val.mmap', 'X_test': 'processed/emb_swin3d_t_test.mmap', 'y_test': 'processed/y_test.mmap'}\n",
      "y_train mean: 0.4930017741980906\n",
      "y_val mean: 0.45839438185216996\n",
      "y_test mean: 0.5198045807942845\n",
      "train counts: [54009 52518]\n",
      "val counts: [10720  9073]\n",
      "test counts: [9141 9895]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"files:\", manifest[\"files\"])\n",
    "\n",
    "print(\"y_train mean:\", float(np.mean(y_train)))\n",
    "print(\"y_val mean:\", float(np.mean(y_val)))\n",
    "print(\"y_test mean:\", float(np.mean(y_test)))\n",
    "\n",
    "# también cuenta clases\n",
    "print(\"train counts:\", np.bincount(np.array(y_train, dtype=np.int64)))\n",
    "print(\"val counts:\",   np.bincount(np.array(y_val, dtype=np.int64)))\n",
    "print(\"test counts:\",  np.bincount(np.array(y_test, dtype=np.int64)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04e1f2-65aa-4fa2-a2df-ee45fcf405e5",
   "metadata": {},
   "source": [
    "### Paso X — Construcción del `Dataset` y `DataLoader` para embeddings (PyTorch)\n",
    "\n",
    "#### ¿Qué se hace en esta celda?\n",
    "Esta celda define un `Dataset` personalizado que envuelve los `memmap` (`X_*`, `y_*`) y luego crea los `DataLoader` de **train / val / test** para alimentar el MLP.\n",
    "\n",
    "Aquí se pasa de:\n",
    "- Datos almacenados en disco (`np.memmap`)\n",
    "a\n",
    "- Tensores PyTorch listos para entrenamiento por batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e788227-b771-4fd9-80e7-681fc9a211c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaders ready.\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X_mm, y_mm):\n",
    "        self.X = X_mm\n",
    "        self.y = y_mm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = np.array(self.X[i], dtype=np.float32)\n",
    "        y = float(self.y[i])\n",
    "        return torch.from_numpy(x), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "train_loader = DataLoader(EmbeddingDataset(X_train, y_train),\n",
    "                          batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "val_loader   = DataLoader(EmbeddingDataset(X_val, y_val),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "test_loader  = DataLoader(EmbeddingDataset(X_test, y_test),\n",
    "                          batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "print(\"Loaders ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12ed08-2155-4001-a1c0-b09130e13bb7",
   "metadata": {},
   "source": [
    "### Paso X — Definición del clasificador MLP y configuración de entrenamiento\n",
    "\n",
    "Aquí se define el **clasificador supervisado** que opera sobre los embeddings `(N, D)` generados por el encoder.  \n",
    "El encoder ya está congelado; este MLP aprende a mapear cada embedding → probabilidad de anomalía.\n",
    "\n",
    "Se configuran además:\n",
    "- función de pérdida,\n",
    "- optimizador,\n",
    "- y se instancia el modelo en el dispositivo (`CPU` o `GPU`).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1918df40-9317-431f-9865-ae3b4c63b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DIINF/dvaldes/venvs/tesis/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim=768):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)  # logits\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = MLP(in_dim=D).to(DEVICE)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de77185-f65b-4bc0-b22c-e99fec644efb",
   "metadata": {},
   "source": [
    "### Paso X — Función de evaluación (`eval_loader`)\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    " Se define `eval_loader(...)`, una función que:\n",
    "- ejecuta el modelo en modo evaluación sobre un `DataLoader`,\n",
    "- obtiene probabilidades,\n",
    "- calcula métricas (AUC, F1, Recall, FAR),\n",
    "- y devuelve además los vectores `(y, p)` para análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afe1a4c3-0a11-4787-aa40-3a60a674c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loader(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            logits = model(xb)\n",
    "            prob = torch.sigmoid(logits)\n",
    "\n",
    "            ys.append(yb.detach().cpu().numpy())\n",
    "            ps.append(prob.detach().cpu().numpy())\n",
    "\n",
    "    y = np.concatenate(ys)\n",
    "    p = np.concatenate(ps)\n",
    "\n",
    "    auc = roc_auc_score(y, p)\n",
    "    yhat = (p >= threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y, yhat)\n",
    "    rec = recall_score(y, yhat)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "    far = fp / (fp + tn + 1e-9)\n",
    "\n",
    "    return {\"auc\": auc, \"f1\": f1, \"recall\": rec, \"far\": far}, (y, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90896d-c293-44f5-9635-3e8bca13b08a",
   "metadata": {},
   "source": [
    "### Paso X — loop de entrenamiento con *early stopping*\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    "\n",
    "Se ejecuta el entrenamiento por épocas:\n",
    "- forward → loss → backward → update,\n",
    "- evaluación en validación por época,\n",
    "- *early stopping* basado en **val AUC**,\n",
    "- y finalmente se restaura el mejor modelo (según AUC de validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbb8e076-12bd-4cf8-ac5c-3e2e9e368dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.0726 | val_auc=0.9012 val_f1=0.8132 val_recall=0.7985 val_far=0.1400\n",
      "Epoch 02 | train_loss=0.0073 | val_auc=0.9002 val_f1=0.8306 val_recall=0.8345 val_far=0.1480\n",
      "Epoch 03 | train_loss=0.0028 | val_auc=0.9007 val_f1=0.7928 val_recall=0.7597 val_far=0.1328\n",
      "Epoch 04 | train_loss=0.0026 | val_auc=0.8947 val_f1=0.8046 val_recall=0.7922 val_far=0.1498\n",
      "Early stopping.\n",
      "Best val AUC: 0.9012041838092685\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "PATIENCE = 3\n",
    "\n",
    "best_auc = -1.0\n",
    "best_state = None\n",
    "bad = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss.detach().cpu().item()))\n",
    "\n",
    "    train_loss = sum(losses) / max(1, len(losses))\n",
    "    val_metrics, _ = eval_loader(model, val_loader, threshold=0.5)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | \"\n",
    "          f\"val_auc={val_metrics['auc']:.4f} val_f1={val_metrics['f1']:.4f} \"\n",
    "          f\"val_recall={val_metrics['recall']:.4f} val_far={val_metrics['far']:.4f}\")\n",
    "\n",
    "    if val_metrics[\"auc\"] > best_auc + 1e-4:\n",
    "        best_auc = val_metrics[\"auc\"]\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Restaurar mejor modelo\n",
    "assert best_state is not None\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Best val AUC:\", best_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1a473-65c1-40c6-93e4-fb6dfa327157",
   "metadata": {},
   "source": [
    "## Paso 1 — Evaluación de desempeño (Validation y Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se evalúa el clasificador MLP sobre los splits **val** y **test** usando `eval_loader`, obteniendo:\n",
    "- métricas principales (AUC, F1, Recall, FAR)\n",
    "- los vectores `(y, p)` para análisis posterior (ROC y matriz de confusión).\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión de métricas por split\n",
    "- Variables listas: `val_metrics`, `test_metrics`, `y_val_np`, `p_val_np`, `y_test_np`, `p_test_np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7036872-57db-4698-81a8-018c1aad4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: {'auc': 0.9012041838092685, 'f1': 0.8131769459565632, 'recall': 0.7985230904882619, 'far': np.float64(0.14001865671640484)}\n",
      "TEST: {'auc': 0.9083872953507728, 'f1': 0.8451028477053201, 'recall': 0.8532592218292067, 'far': np.float64(0.17973963461326115)}\n"
     ]
    }
   ],
   "source": [
    "val_metrics, (y_val_np, p_val_np) = eval_loader(model, val_loader, threshold=0.5)\n",
    "test_metrics, (y_test_np, p_test_np) = eval_loader(model, test_loader, threshold=0.5)\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3410538-38ac-42b4-a773-aa4c132b4086",
   "metadata": {},
   "source": [
    "## Paso 2 — Matriz de confusión (Test) + métrica de Accuracy\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se fija un umbral (`0.5`) para convertir probabilidades en clases 0/1, y se calcula:\n",
    "- `Accuracy`\n",
    "- Matriz de confusión: TN, FP, FN, TP\n",
    "\n",
    "### Resultado esperado\n",
    "- Matriz de confusión (tabla 2×2)\n",
    "- Valores TN/FP/FN/TP impresos\n",
    "- Accuracy impresa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58216e66-0a9d-4c7e-a655-440662f52825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion Matrix (TEST) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>7498</td>\n",
       "      <td>1643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>1452</td>\n",
       "      <td>8443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0    7498    1643\n",
       "Actual 1    1452    8443"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN=7498 FP=1643 FN=1452 TP=8443\n",
      "Accuracy (TEST) = 0.8374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.5\n",
    "y_test_bin = (p_test_np >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_np, y_test_bin)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc_test = accuracy_score(y_test_np, y_test_bin)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (TEST) ===\")\n",
    "display(cm_df)\n",
    "print(f\"TN={tn} FP={fp} FN={fn} TP={tp}\")\n",
    "print(f\"Accuracy (TEST) = {acc_test:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f986491-acdd-4c13-85fb-c0ae89d4e722",
   "metadata": {},
   "source": [
    "## Paso 3 — Curva ROC (Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se construye y grafica la curva ROC con:\n",
    "- FPR (False Positive Rate)\n",
    "- TPR (True Positive Rate)\n",
    "\n",
    "### Resultado esperado\n",
    "- Gráfico ROC del split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06a108da-9243-4335-9a08-487bd9d0f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_np, p_test_np)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC - TimeSformer (CLS) + MLP (TEST)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c2fa8-d005-4b5a-a313-b3154df60e53",
   "metadata": {},
   "source": [
    "## Paso 4 — Tabla resumen de desempeño (Validation vs Test) y guardado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se genera una tabla final con métricas de desempeño (val/test) y se guarda en CSV.\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `results_df`\n",
    "- Archivo CSV exportado a `processed/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70789050-60c6-4344-83f4-50a0b1101f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados de Desempeño: TimeSformer (CLS) + MLP ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Split</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FAR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Validation</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.7985</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.8318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Test</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.8374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Split     AUC      F1  Recall     FAR  Accuracy\n",
       "0  Validation  0.9012  0.8132  0.7985  0.1400    0.8318\n",
       "1        Test  0.9084  0.8451  0.8533  0.1797    0.8374"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/results_performance_swin.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Split\": [\"Validation\", \"Test\"],\n",
    "    \"AUC\": [val_metrics[\"auc\"], test_metrics[\"auc\"]],\n",
    "    \"F1\": [val_metrics[\"f1\"], test_metrics[\"f1\"]],\n",
    "    \"Recall\": [val_metrics[\"recall\"], test_metrics[\"recall\"]],\n",
    "    \"FAR\": [val_metrics[\"far\"], test_metrics[\"far\"]],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_val_np, (p_val_np >= threshold).astype(int)),\n",
    "        accuracy_score(y_test_np, (p_test_np >= threshold).astype(int)),\n",
    "    ],\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n=== Resultados de Desempeño: TimeSformer (CLS) + MLP ===\\n\")\n",
    "display(results_df)\n",
    "\n",
    "out_csv = PROCESSED / \"results_performance_swin.csv\"\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de694c0f-224f-4fba-9d8d-37dde1a64a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def uniform_sample_indices(start_f: int, end_f: int, T: int):\n",
    "    n = max(1, end_f - start_f)\n",
    "    idx = np.linspace(0, n - 1, T).round().astype(int)\n",
    "    return (start_f + idx).astype(int)\n",
    "\n",
    "class ClipDataset(Dataset):\n",
    "    def __init__(self, df, T=8, img_size=224):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.T = T\n",
    "        self.img_size = img_size\n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "        self.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"path\"]\n",
    "        start_f = int(row[\"start_frame\"])\n",
    "        end_f   = int(row[\"end_frame\"])\n",
    "        y = int(row[\"y\"])\n",
    "\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(f\"No pude abrir video: {path}\")\n",
    "\n",
    "        frame_ids = uniform_sample_indices(start_f, end_f, self.T)\n",
    "\n",
    "        frames = []\n",
    "        last_good = None\n",
    "        for fid in frame_ids:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))\n",
    "            ok, frame = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                frame = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8) if last_good is None else last_good\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "                last_good = frame\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        arr = np.stack(frames).astype(np.float32) / 255.0\n",
    "        arr = (arr - self.mean) / self.std\n",
    "        arr = np.transpose(arr, (3, 0, 1, 2))  # (C,T,H,W)\n",
    "        clip = torch.from_numpy(arr)\n",
    "\n",
    "        return clip, torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51a66a-f949-4f30-8ae5-21f8ab3d317a",
   "metadata": {},
   "source": [
    "## Paso 5 — Métricas operativas del encoder (latencia, ms/frame, FPS)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se mide el tiempo de inferencia del encoder TimeSformer sobre batches reales:\n",
    "- warmup (no medir los primeros batches)\n",
    "- medición promedio por batch\n",
    "- latencia por clip\n",
    "- ms/frame\n",
    "- FPS efectivo\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión: avg s/batch, ms/clip, ms/frame, FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "875045e6-f9af-48ad-a693-ef4a8811b940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 5: Métricas Operativas (Encoder Swin3D) ===\n",
      "T: 8 IMG_SIZE: 224\n",
      "DEVICE: cuda\n",
      "\n",
      "Batches medidos: 200\n",
      "Batch size: 8\n",
      "Tiempo promedio por batch: 0.0733 s\n",
      "Latencia por clip: 9.16 ms/clip\n",
      "Tiempo por frame: 1.15 ms/frame\n",
      "FPS efectivo: 873.22 fps\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 5 — Métricas operativas del encoder (Swin3D)\n",
    "# =========================\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models.video import swin3d_t, Swin3D_T_Weights\n",
    "\n",
    "# 1) Variables desde manifest\n",
    "T = int(manifest[\"T\"])\n",
    "IMG_SIZE = int(manifest[\"img_size\"])\n",
    "\n",
    "print(\"\\n=== Paso 5: Métricas Operativas (Encoder Swin3D) ===\")\n",
    "print(\"T:\", T, \"IMG_SIZE:\", IMG_SIZE)\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# 2) Cargar encoder Swin3D (mismo que usaste para embeddings)\n",
    "WEIGHTS = Swin3D_T_Weights.DEFAULT\n",
    "encoder = swin3d_t(weights=WEIGHTS).to(DEVICE)\n",
    "encoder.head = nn.Identity()  # quitamos clasificador para medir backbone\n",
    "encoder.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_encoder_latency(\n",
    "    encoder,\n",
    "    T: int,\n",
    "    img_size: int,\n",
    "    device: str,\n",
    "    batch_size: int = 8,\n",
    "    n_batches: int = 200,\n",
    "    warmup: int = 10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Mide latencia del forward del encoder Swin3D con input dummy.\n",
    "    Input esperado: (B, C, T, H, W)\n",
    "    \"\"\"\n",
    "\n",
    "    dummy = torch.randn(batch_size, 3, T, img_size, img_size, device=device)\n",
    "\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = encoder(dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    for _ in range(n_batches):\n",
    "        _ = encoder(dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    time_per_batch_s = elapsed / n_batches\n",
    "    time_per_clip_s  = time_per_batch_s / batch_size\n",
    "    time_per_frame_s = time_per_clip_s / T\n",
    "    fps_effective    = 1.0 / time_per_frame_s\n",
    "\n",
    "    return {\n",
    "        \"batches_measured\": int(n_batches),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"T\": int(T),\n",
    "        \"img_size\": int(img_size),\n",
    "        \"time_per_batch_s\": float(time_per_batch_s),\n",
    "        \"time_per_clip_s\": float(time_per_clip_s),\n",
    "        \"time_per_frame_s\": float(time_per_frame_s),\n",
    "        \"fps_effective\": float(fps_effective),\n",
    "    }\n",
    "\n",
    "# 3) Ejecutar medición\n",
    "op = measure_encoder_latency(\n",
    "    encoder=encoder,\n",
    "    T=T,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    batch_size=8,  # ajusta según VRAM\n",
    "    n_batches=200,\n",
    "    warmup=10,\n",
    ")\n",
    "\n",
    "time_per_clip  = op[\"time_per_clip_s\"]\n",
    "time_per_frame = op[\"time_per_frame_s\"]\n",
    "fps_effective  = op[\"fps_effective\"]\n",
    "\n",
    "print(\"\\nBatches medidos:\", op[\"batches_measured\"])\n",
    "print(\"Batch size:\", op[\"batch_size\"])\n",
    "print(f\"Tiempo promedio por batch: {op['time_per_batch_s']:.4f} s\")\n",
    "print(f\"Latencia por clip: {time_per_clip*1000:.2f} ms/clip\")\n",
    "print(f\"Tiempo por frame: {time_per_frame*1000:.2f} ms/frame\")\n",
    "print(f\"FPS efectivo: {fps_effective:.2f} fps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713a841-343a-4c67-8c9b-045fd7ad4386",
   "metadata": {},
   "source": [
    "## Paso 6 — Time-To-Alert (TTA) estimado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima un **time-to-alert** aproximado como:\n",
    "- duración temporal de la ventana (clip) = `T / fps_video`\n",
    "- + latencia computacional (ms/clip)\n",
    "\n",
    "### Resultado esperado\n",
    "- Duración ventana\n",
    "- Latencia computacional\n",
    "- TTA estimado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf85616f-cb20-4794-b0a4-041b8d6b73e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 6: Time-To-Alert (TTA) ===\n",
      "FPS video asumido: 30\n",
      "Duración ventana (clip): 0.267 s\n",
      "Latencia computacional: 0.009 s\n",
      "Time-To-Alert estimado: 0.276 s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 6 — Time-To-Alert (TTA) estimado\n",
    "# =========================\n",
    "# Requiere: T, time_per_clip (calculado en Paso 5)\n",
    "video_fps = 30  # ajusta si tu fuente es distinta\n",
    "\n",
    "latencia_clip_ms = time_per_clip * 1000.0\n",
    "duracion_clip_s = T / video_fps\n",
    "tta_s = duracion_clip_s + (latencia_clip_ms / 1000.0)\n",
    "\n",
    "print(\"\\n=== Paso 6: Time-To-Alert (TTA) ===\")\n",
    "print(f\"FPS video asumido: {video_fps}\")\n",
    "print(f\"Duración ventana (clip): {duracion_clip_s:.3f} s\")\n",
    "print(f\"Latencia computacional: {latencia_clip_ms/1000:.3f} s\")\n",
    "print(f\"Time-To-Alert estimado: {tta_s:.3f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33515a13-2293-400a-9613-f7e5b9bba057",
   "metadata": {},
   "source": [
    "## Paso 7 — Complejidad computacional (FLOPs y parámetros)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima:\n",
    "- GFLOPs del encoder\n",
    "- número de parámetros\n",
    "\n",
    "Usando `thop` sobre un tensor dummy con forma compatible.\n",
    "\n",
    "### Resultado esperado\n",
    "- GFLOPs\n",
    "- Params (millones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84dbf875-35a6-45d1-bd1c-51a6028f0fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 7: Complejidad Computacional (Swin3D) ===\n",
      "FLOPs: 35.90 GFLOPs\n",
      "Parámetros: 18.86 M\n"
     ]
    }
   ],
   "source": [
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "# dummy correcto para Swin3D: (B, C, T, H, W)\n",
    "dummy = torch.randn(1, 3, T, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "# THOP: en Swin3D usualmente funciona directo\n",
    "try:\n",
    "    flops, params = profile(encoder, inputs=(dummy,), verbose=False)\n",
    "except Exception as e:\n",
    "    print(\"THOP falló con error:\", repr(e))\n",
    "\n",
    "    # Wrapper fallback (solo forward posicional)\n",
    "    class EncoderWrapper(torch.nn.Module):\n",
    "        def __init__(self, enc):\n",
    "            super().__init__()\n",
    "            self.enc = enc\n",
    "        def forward(self, x):\n",
    "            return self.enc(x)\n",
    "\n",
    "    wrapped = EncoderWrapper(encoder).to(DEVICE).eval()\n",
    "    flops, params = profile(wrapped, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(\"\\n=== Paso 7: Complejidad Computacional (Swin3D) ===\")\n",
    "print(f\"FLOPs: {flops/1e9:.2f} GFLOPs\")\n",
    "print(f\"Parámetros: {params/1e6:.2f} M\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c48383-a294-4ce4-9354-75f484ea1b53",
   "metadata": {},
   "source": [
    "## Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se arma una tabla única para reportar en tesis, combinando:\n",
    "- desempeño (Test)\n",
    "- métricas operativas (ms/frame, FPS, TTA)\n",
    "- costo computacional (GFLOPs)\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `final_table`\n",
    "- CSV exportado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15d9d5cc-3b83-423a-9b93-f3ee633b3824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>FAR (Test)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>ms/frame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>TTA (s)</th>\n",
       "      <th>GFLOPs</th>\n",
       "      <th>Params (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Swin + MLP</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>7498</td>\n",
       "      <td>1643</td>\n",
       "      <td>1452</td>\n",
       "      <td>8443</td>\n",
       "      <td>1.15</td>\n",
       "      <td>873.22</td>\n",
       "      <td>0.276</td>\n",
       "      <td>35.9</td>\n",
       "      <td>18.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Modelo  AUC (Test)  F1 (Test)  Recall (Test)  FAR (Test)  \\\n",
       "0  Swin + MLP      0.9084     0.8451         0.8533      0.1797   \n",
       "\n",
       "   Accuracy (Test)    TN    FP    FN    TP  ms/frame     FPS  TTA (s)  GFLOPs  \\\n",
       "0           0.8374  7498  1643  1452  8443      1.15  873.22    0.276    35.9   \n",
       "\n",
       "   Params (M)  \n",
       "0       18.86  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/final_report_swin_full.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "# =========================\n",
    "# Requiere: test_metrics, acc_test, tn, fp, fn, tp, flops, params, tta_s,\n",
    "#           time_per_frame, fps_effective, y objeto Path/dir PROCESSED (o usa string)\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Ajusta esta ruta si tu proyecto usa otra variable (PROCESSED_DIR, etc.)\n",
    "PROCESSED = Path(\"processed\")\n",
    "\n",
    "final_table = pd.DataFrame({\n",
    "    \"Modelo\": [\"Swin + MLP\"],\n",
    "    \"AUC (Test)\": [round(test_metrics[\"auc\"], 4)],\n",
    "    \"F1 (Test)\": [round(test_metrics[\"f1\"], 4)],\n",
    "    \"Recall (Test)\": [round(test_metrics[\"recall\"], 4)],\n",
    "    \"FAR (Test)\": [round(test_metrics[\"far\"], 4)],\n",
    "    \"Accuracy (Test)\": [round(float(acc_test), 4)],\n",
    "    \"TN\": [int(tn)], \"FP\": [int(fp)], \"FN\": [int(fn)], \"TP\": [int(tp)],\n",
    "    \"ms/frame\": [round(time_per_frame * 1000.0, 2)],\n",
    "    \"FPS\": [round(float(fps_effective), 2)],\n",
    "    \"TTA (s)\": [round(float(tta_s), 3)],\n",
    "    \"GFLOPs\": [round(float(flops/1e9), 2)],\n",
    "    \"Params (M)\": [round(float(params/1e6), 2)],\n",
    "})\n",
    "\n",
    "display(final_table)\n",
    "\n",
    "out_csv = PROCESSED / \"final_report_swin_full.csv\"\n",
    "final_table.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e2aa0-86fb-49d3-85f3-501c4ad90558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
