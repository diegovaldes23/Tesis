{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b4f1f5f-d455-42fb-8225-4a87fc325e42",
   "metadata": {},
   "source": [
    "# MLP sobre embeddings CLS (TimeSformer Frozen)\n",
    "\n",
    "Este notebook entrena un clasificador MLP binario usando embeddings CLS precomputados de TimeSformer.\n",
    "Entrada: archivos `.mmap` en `processed/`.\n",
    "Salida: métricas (AUC, F1, Recall, FAR) y artefactos de resultados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fbaa326-eb01-4ff1-ac5e-e5a8324cdb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "Model: microsoft/xclip-base-patch32\n",
      "T: 8 IMG_SIZE: 224 D: 512\n",
      "dtypes -> X: float16 | y: int8\n",
      "N_train, N_val, N_test: 106527 19793 19036\n",
      "X_train shape: (106527, 512) dtype: float16\n",
      "y_train counts: [54009 52518]\n",
      "y_val counts: [10720  9073]\n",
      "y_test counts: [9141 9895]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, confusion_matrix, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# =========================\n",
    "# Helpers para abrir memmaps\n",
    "# =========================\n",
    "def infer_1d_length(file_path: Path, dtype: str) -> int:\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    assert nbytes % item == 0, f\"Tamaño de archivo no calza con dtype={dtype}\"\n",
    "    return nbytes // item\n",
    "\n",
    "def open_y(file_path: Path, dtype=\"int8\"):\n",
    "    N = infer_1d_length(file_path, dtype)\n",
    "    return np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N,))\n",
    "\n",
    "def open_X(file_path: Path, N: int, D: int, dtype=\"float16\"):\n",
    "    nbytes = file_path.stat().st_size\n",
    "    item = np.dtype(dtype).itemsize\n",
    "    expected = N * D * item\n",
    "    assert nbytes == expected, f\"X size mismatch. got={nbytes}, expected={expected} (N={N}, D={D}, dtype={dtype})\"\n",
    "    return np.memmap(file_path, mode=\"r\", dtype=dtype, shape=(N, D))\n",
    "\n",
    "# =========================\n",
    "# Cargar manifest VideoCLIP/XCLIP\n",
    "# =========================\n",
    "PROCESSED = Path(\"processed\")\n",
    "MANIFEST_PATH = PROCESSED / \"manifest_xclip_video.json\"\n",
    "assert MANIFEST_PATH.exists(), f\"No existe {MANIFEST_PATH}\"\n",
    "\n",
    "with open(MANIFEST_PATH, \"r\") as f:\n",
    "    manifest = json.load(f)\n",
    "\n",
    "files = manifest[\"files\"]\n",
    "D = int(manifest[\"embedding_dim\"])\n",
    "\n",
    "X_DTYPE = manifest.get(\"x_dtype\", \"float16\")\n",
    "Y_DTYPE = manifest.get(\"y_dtype\", \"int8\")\n",
    "\n",
    "print(\"Model:\", manifest[\"model\"])\n",
    "print(\"T:\", manifest[\"T\"], \"IMG_SIZE:\", manifest[\"img_size\"], \"D:\", D)\n",
    "print(\"dtypes -> X:\", X_DTYPE, \"| y:\", Y_DTYPE)\n",
    "\n",
    "# Abrir y primero (para inferir N)\n",
    "y_train = open_y(Path(files[\"y_train\"]), dtype=Y_DTYPE)\n",
    "y_val   = open_y(Path(files[\"y_val\"]), dtype=Y_DTYPE)\n",
    "y_test  = open_y(Path(files[\"y_test\"]), dtype=Y_DTYPE)\n",
    "\n",
    "N_train, N_val, N_test = len(y_train), len(y_val), len(y_test)\n",
    "print(\"N_train, N_val, N_test:\", N_train, N_val, N_test)\n",
    "\n",
    "# Abrir X con shapes correctas (N, D)\n",
    "X_train = open_X(Path(files[\"X_train\"]), N_train, D, dtype=X_DTYPE)\n",
    "X_val   = open_X(Path(files[\"X_val\"]),   N_val,   D, dtype=X_DTYPE)\n",
    "X_test  = open_X(Path(files[\"X_test\"]),  N_test,  D, dtype=X_DTYPE)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape, \"dtype:\", X_train.dtype)\n",
    "\n",
    "# sanity: distribución\n",
    "print(\"y_train counts:\", np.bincount(np.array(y_train, dtype=np.int64)))\n",
    "print(\"y_val counts:\",   np.bincount(np.array(y_val, dtype=np.int64)))\n",
    "print(\"y_test counts:\",  np.bincount(np.array(y_test, dtype=np.int64)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bb9f47-f02a-45a7-974b-de553325e9b2",
   "metadata": {},
   "source": [
    "### Paso X — Carga del *manifest* y apertura de embeddings con `memmap` (train/val/test)\n",
    "\n",
    "Esta celda **carga el archivo `manifest.json`** del experimento y luego **abre (sin cargar a RAM)** los archivos binarios (`.bin`/`.dat`) que contienen:\n",
    "\n",
    "- `y_train`, `y_val`, `y_test`: etiquetas (0/1) guardadas como vector 1D (`int8`).\n",
    "- `X_train`, `X_val`, `X_test`: embeddings del codificador guardados como matriz 2D (`float16`) de forma `(N, D)`.\n",
    "\n",
    "La idea central es usar **`np.memmap`** para trabajar con datasets grandes: se mapean desde disco y se leen “on demand”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04e1f2-65aa-4fa2-a2df-ee45fcf405e5",
   "metadata": {},
   "source": [
    "### Paso X — Construcción del `Dataset` y `DataLoader` para embeddings (PyTorch)\n",
    "\n",
    "#### ¿Qué se hace en esta celda?\n",
    "Esta celda define un `Dataset` personalizado que envuelve los `memmap` (`X_*`, `y_*`) y luego crea los `DataLoader` de **train / val / test** para alimentar el MLP.\n",
    "\n",
    "Aquí se pasa de:\n",
    "- Datos almacenados en disco (`np.memmap`)\n",
    "a\n",
    "- Tensores PyTorch listos para entrenamiento por batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e788227-b771-4fd9-80e7-681fc9a211c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, X_mm, y_mm):\n",
    "        self.X = X_mm\n",
    "        self.y = y_mm\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x = np.asarray(self.X[i], dtype=np.float32)              # (D,)\n",
    "        y = np.float32(self.y[i])                                # 0/1 en float32\n",
    "        return torch.from_numpy(x), torch.tensor(y)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "pin = (DEVICE == \"cuda\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EmbeddingDataset(X_train, y_train),\n",
    "    batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    EmbeddingDataset(X_val, y_val),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    EmbeddingDataset(X_test, y_test),\n",
    "    batch_size=BATCH_SIZE, shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=pin,\n",
    "    persistent_workers=(NUM_WORKERS > 0),\n",
    "    prefetch_factor=4 if NUM_WORKERS > 0 else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12ed08-2155-4001-a1c0-b09130e13bb7",
   "metadata": {},
   "source": [
    "### Paso X — Definición del clasificador MLP y configuración de entrenamiento\n",
    "\n",
    "Aquí se define el **clasificador supervisado** que opera sobre los embeddings `(N, D)` generados por el encoder.  \n",
    "El encoder ya está congelado; este MLP aprende a mapear cada embedding → probabilidad de anomalía.\n",
    "\n",
    "Se configuran además:\n",
    "- función de pérdida,\n",
    "- optimizador,\n",
    "- y se instancia el modelo en el dispositivo (`CPU` o `GPU`).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1918df40-9317-431f-9865-ae3b4c63b894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DIINF/dvaldes/venvs/tesis/lib/python3.10/site-packages/torch/cuda/__init__.py:827: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (net): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.2, inplace=False)\n",
      "    (6): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)\n",
    "\n",
    "model = MLP(in_dim=D).to(DEVICE)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de77185-f65b-4bc0-b22c-e99fec644efb",
   "metadata": {},
   "source": [
    "### Paso X — Función de evaluación (`eval_loader`)\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    " Se define `eval_loader(...)`, una función que:\n",
    "- ejecuta el modelo en modo evaluación sobre un `DataLoader`,\n",
    "- obtiene probabilidades,\n",
    "- calcula métricas (AUC, F1, Recall, FAR),\n",
    "- y devuelve además los vectores `(y, p)` para análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afe1a4c3-0a11-4787-aa40-3a60a674c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loader(model, loader, threshold=0.5):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in loader:\n",
    "            xb = xb.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "            logits = model(xb)\n",
    "            prob = torch.sigmoid(logits)\n",
    "\n",
    "            ys.append(yb.detach().cpu().numpy())\n",
    "            ps.append(prob.detach().cpu().numpy())\n",
    "\n",
    "    y = np.concatenate(ys)\n",
    "    p = np.concatenate(ps)\n",
    "\n",
    "    auc = roc_auc_score(y, p)\n",
    "    yhat = (p >= threshold).astype(int)\n",
    "\n",
    "    f1 = f1_score(y, yhat)\n",
    "    rec = recall_score(y, yhat)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y, yhat).ravel()\n",
    "    far = fp / (fp + tn + 1e-9)\n",
    "\n",
    "    return {\"auc\": auc, \"f1\": f1, \"recall\": rec, \"far\": far}, (y, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90896d-c293-44f5-9635-3e8bca13b08a",
   "metadata": {},
   "source": [
    "### Paso X — loop de entrenamiento con *early stopping*\n",
    "\n",
    "#### ¿Qué se hace en estas celdas?\n",
    "\n",
    "Se ejecuta el entrenamiento por épocas:\n",
    "- forward → loss → backward → update,\n",
    "- evaluación en validación por época,\n",
    "- *early stopping* basado en **val AUC**,\n",
    "- y finalmente se restaura el mejor modelo (según AUC de validación)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbb8e076-12bd-4cf8-ac5c-3e2e9e368dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 | train_loss=0.6938 | val_auc=0.4170 val_f1=0.0009 val_recall=0.0004 val_far=0.0035\n",
      "Epoch 02 | train_loss=0.6930 | val_auc=0.5144 val_f1=0.0258 val_recall=0.0132 val_far=0.0106\n",
      "Epoch 03 | train_loss=0.6930 | val_auc=0.6299 val_f1=0.1553 val_recall=0.0878 val_far=0.0369\n",
      "Epoch 04 | train_loss=0.6926 | val_auc=0.6512 val_f1=0.1485 val_recall=0.0863 val_far=0.0645\n",
      "Epoch 05 | train_loss=0.6925 | val_auc=0.5508 val_f1=0.2902 val_recall=0.2013 val_far=0.1574\n",
      "Epoch 06 | train_loss=0.6920 | val_auc=0.4800 val_f1=0.2299 val_recall=0.1388 val_far=0.0578\n",
      "Epoch 07 | train_loss=0.6915 | val_auc=0.5601 val_f1=0.3403 val_recall=0.2421 val_far=0.1531\n",
      "Early stopping.\n",
      "Best val AUC: 0.6511685585902736\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "PATIENCE = 3\n",
    "\n",
    "best_auc = -1.0\n",
    "best_state = None\n",
    "bad = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for xb, yb in train_loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.append(float(loss.detach().cpu().item()))\n",
    "\n",
    "    train_loss = sum(losses) / max(1, len(losses))\n",
    "    val_metrics, _ = eval_loader(model, val_loader, threshold=0.5)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train_loss={train_loss:.4f} | \"\n",
    "          f\"val_auc={val_metrics['auc']:.4f} val_f1={val_metrics['f1']:.4f} \"\n",
    "          f\"val_recall={val_metrics['recall']:.4f} val_far={val_metrics['far']:.4f}\")\n",
    "\n",
    "    if val_metrics[\"auc\"] > best_auc + 1e-4:\n",
    "        best_auc = val_metrics[\"auc\"]\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "        bad = 0\n",
    "    else:\n",
    "        bad += 1\n",
    "        if bad >= PATIENCE:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "# Restaurar mejor modelo\n",
    "assert best_state is not None\n",
    "model.load_state_dict(best_state)\n",
    "print(\"Best val AUC:\", best_auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c1a473-65c1-40c6-93e4-fb6dfa327157",
   "metadata": {},
   "source": [
    "## Paso 1 — Evaluación de desempeño (Validation y Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se evalúa el clasificador MLP sobre los splits **val** y **test** usando `eval_loader`, obteniendo:\n",
    "- métricas principales (AUC, F1, Recall, FAR)\n",
    "- los vectores `(y, p)` para análisis posterior (ROC y matriz de confusión).\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión de métricas por split\n",
    "- Variables listas: `val_metrics`, `test_metrics`, `y_val_np`, `p_val_np`, `y_test_np`, `p_test_np`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7036872-57db-4698-81a8-018c1aad4cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL: {'auc': 0.6511685585902736, 'f1': 0.14847824025789325, 'recall': 0.08630001102171278, 'far': np.float64(0.06445895522387458)}\n",
      "TEST: {'auc': 0.48317376761874314, 'f1': 0.050302168503377175, 'recall': 0.028600303183425973, 'far': np.float64(0.11749261568754868)}\n"
     ]
    }
   ],
   "source": [
    "val_metrics, (y_val_np, p_val_np) = eval_loader(model, val_loader, threshold=0.5)\n",
    "test_metrics, (y_test_np, p_test_np) = eval_loader(model, test_loader, threshold=0.5)\n",
    "\n",
    "print(\"VAL:\", val_metrics)\n",
    "print(\"TEST:\", test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3410538-38ac-42b4-a773-aa4c132b4086",
   "metadata": {},
   "source": [
    "## Paso 2 — Matriz de confusión (Test) + métrica de Accuracy\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se fija un umbral (`0.5`) para convertir probabilidades en clases 0/1, y se calcula:\n",
    "- `Accuracy`\n",
    "- Matriz de confusión: TN, FP, FN, TP\n",
    "\n",
    "### Resultado esperado\n",
    "- Matriz de confusión (tabla 2×2)\n",
    "- Valores TN/FP/FN/TP impresos\n",
    "- Accuracy impresa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58216e66-0a9d-4c7e-a655-440662f52825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Confusion Matrix (TEST) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>8067</td>\n",
       "      <td>1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>9612</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pred 0  Pred 1\n",
       "Actual 0    8067    1074\n",
       "Actual 1    9612     283"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN=8067 FP=1074 FN=9612 TP=283\n",
      "Accuracy (TEST) = 0.4386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "threshold = 0.5\n",
    "y_test_bin = (p_test_np >= threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test_np, y_test_bin)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "acc_test = accuracy_score(y_test_np, y_test_bin)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Pred 0\", \"Pred 1\"])\n",
    "\n",
    "print(\"\\n=== Confusion Matrix (TEST) ===\")\n",
    "display(cm_df)\n",
    "print(f\"TN={tn} FP={fp} FN={fn} TP={tp}\")\n",
    "print(f\"Accuracy (TEST) = {acc_test:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f986491-acdd-4c13-85fb-c0ae89d4e722",
   "metadata": {},
   "source": [
    "## Paso 3 — Curva ROC (Test)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se construye y grafica la curva ROC con:\n",
    "- FPR (False Positive Rate)\n",
    "- TPR (True Positive Rate)\n",
    "\n",
    "### Resultado esperado\n",
    "- Gráfico ROC del split test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a108da-9243-4335-9a08-487bd9d0f4be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test_np, p_test_np)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC - TimeSformer (CLS) + MLP (TEST)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c2fa8-d005-4b5a-a313-b3154df60e53",
   "metadata": {},
   "source": [
    "## Paso 4 — Tabla resumen de desempeño (Validation vs Test) y guardado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se genera una tabla final con métricas de desempeño (val/test) y se guarda en CSV.\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `results_df`\n",
    "- Archivo CSV exportado a `processed/`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70789050-60c6-4344-83f4-50a0b1101f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Resultados de Desempeño: microsoft/xclip-base-patch32 + MLP ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Split</th>\n",
       "      <th>AUC</th>\n",
       "      <th>F1</th>\n",
       "      <th>Recall</th>\n",
       "      <th>FAR</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/xclip-base-patch32 + MLP</td>\n",
       "      <td>Validation</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.1485</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.5463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/xclip-base-patch32 + MLP</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Modelo       Split     AUC      F1  Recall  \\\n",
       "0  microsoft/xclip-base-patch32 + MLP  Validation  0.6512  0.1485  0.0863   \n",
       "1  microsoft/xclip-base-patch32 + MLP        Test  0.4832  0.0503  0.0286   \n",
       "\n",
       "      FAR  Accuracy  \n",
       "0  0.0645    0.5463  \n",
       "1  0.1175    0.4386  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/results_performance_videoclip_mlp.csv\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "# Asegurar threshold explícito\n",
    "threshold = 0.5\n",
    "\n",
    "MODEL_LABEL = f\"{manifest.get('model', 'VideoCLIP')} + MLP\"\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    \"Modelo\": [MODEL_LABEL, MODEL_LABEL],\n",
    "    \"Split\": [\"Validation\", \"Test\"],\n",
    "    \"AUC\": [val_metrics[\"auc\"], test_metrics[\"auc\"]],\n",
    "    \"F1\": [val_metrics[\"f1\"], test_metrics[\"f1\"]],\n",
    "    \"Recall\": [val_metrics[\"recall\"], test_metrics[\"recall\"]],\n",
    "    \"FAR\": [val_metrics[\"far\"], test_metrics[\"far\"]],\n",
    "    \"Accuracy\": [\n",
    "        accuracy_score(y_val_np, (p_val_np >= threshold).astype(int)),\n",
    "        accuracy_score(y_test_np, (p_test_np >= threshold).astype(int)),\n",
    "    ],\n",
    "}).round(4)\n",
    "\n",
    "print(f\"\\n=== Resultados de Desempeño: {MODEL_LABEL} ===\\n\")\n",
    "display(results_df)\n",
    "\n",
    "out_csv = PROCESSED / \"results_performance_videoclip_mlp.csv\"\n",
    "results_df.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de694c0f-224f-4fba-9d8d-37dde1a64a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def uniform_sample_indices(start_f: int, end_f: int, T: int):\n",
    "    n = max(1, end_f - start_f)\n",
    "    idx = np.linspace(0, n - 1, T).round().astype(int)\n",
    "    return (start_f + idx).astype(int)\n",
    "\n",
    "class ClipDataset(Dataset):\n",
    "    def __init__(self, df, T=8, img_size=224):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.T = T\n",
    "        self.img_size = img_size\n",
    "        self.mean = np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "        self.std  = np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        row = self.df.iloc[i]\n",
    "        path = row[\"path\"]\n",
    "        start_f = int(row[\"start_frame\"])\n",
    "        end_f   = int(row[\"end_frame\"])\n",
    "        y = int(row[\"y\"])\n",
    "\n",
    "        cap = cv2.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            raise RuntimeError(f\"No pude abrir video: {path}\")\n",
    "\n",
    "        frame_ids = uniform_sample_indices(start_f, end_f, self.T)\n",
    "\n",
    "        frames = []\n",
    "        last_good = None\n",
    "        for fid in frame_ids:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, int(fid))\n",
    "            ok, frame = cap.read()\n",
    "\n",
    "            if not ok:\n",
    "                frame = np.zeros((self.img_size, self.img_size, 3), dtype=np.uint8) if last_good is None else last_good\n",
    "            else:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                frame = cv2.resize(frame, (self.img_size, self.img_size), interpolation=cv2.INTER_LINEAR)\n",
    "                last_good = frame\n",
    "\n",
    "            frames.append(frame)\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        arr = np.stack(frames).astype(np.float32) / 255.0\n",
    "        arr = (arr - self.mean) / self.std\n",
    "        arr = np.transpose(arr, (3, 0, 1, 2))  # (C,T,H,W)\n",
    "        clip = torch.from_numpy(arr)\n",
    "\n",
    "        return clip, torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd51a66a-f949-4f30-8ae5-21f8ab3d317a",
   "metadata": {},
   "source": [
    "## Paso 5 — Métricas operativas del encoder (latencia, ms/frame, FPS)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se mide el tiempo de inferencia del encoder TimeSformer sobre batches reales:\n",
    "- warmup (no medir los primeros batches)\n",
    "- medición promedio por batch\n",
    "- latencia por clip\n",
    "- ms/frame\n",
    "- FPS efectivo\n",
    "\n",
    "### Resultado esperado\n",
    "- Impresión: avg s/batch, ms/clip, ms/frame, FPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2f0972b-897d-4901-8ddd-4d7cce1eb91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 5: Métricas Operativas (Encoder VideoCLIP/XCLIP) ===\n",
      "Checkpoint: microsoft/xclip-base-patch32\n",
      "T: 8 IMG_SIZE: 224\n",
      "DEVICE: cuda\n",
      "\n",
      "Batches medidos: 200\n",
      "Batch size: 8\n",
      "Tiempo promedio por batch: 0.0683 s\n",
      "Latencia por clip: 8.54 ms/clip\n",
      "Tiempo por frame: 1.07 ms/frame\n",
      "FPS efectivo: 936.57 fps\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 5 — Métricas operativas del encoder (VideoCLIP / XCLIP)\n",
    "# latencia, ms/clip, ms/frame, FPS\n",
    "# =========================\n",
    "import time\n",
    "import torch\n",
    "from transformers import XCLIPModel\n",
    "\n",
    "# 1) Variables desde el manifest (ajusta claves si tu manifest usa otros nombres)\n",
    "T = int(manifest.get(\"T\", manifest.get(\"clip_len\", 16)))\n",
    "IMG_SIZE = int(manifest.get(\"img_size\", manifest.get(\"image_size\", 224)))\n",
    "\n",
    "# Importante: que el checkpoint sea el mismo que usaste al generar embeddings\n",
    "XCLIP_CKPT = manifest.get(\"model\", manifest.get(\"ckpt\", \"microsoft/xclip-base-patch32\"))\n",
    "\n",
    "print(\"\\n=== Paso 5: Métricas Operativas (Encoder VideoCLIP/XCLIP) ===\")\n",
    "print(\"Checkpoint:\", XCLIP_CKPT)\n",
    "print(\"T:\", T, \"IMG_SIZE:\", IMG_SIZE)\n",
    "print(\"DEVICE:\", DEVICE)\n",
    "\n",
    "# 2) Cargar encoder\n",
    "encoder = XCLIPModel.from_pretrained(XCLIP_CKPT).to(DEVICE)\n",
    "encoder.eval()\n",
    "\n",
    "@torch.no_grad()\n",
    "def xclip_video_embeds_unimodal(encoder: XCLIPModel, pixel_values: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    pixel_values: (B, T, C, H, W)\n",
    "    return: (B, D) video embedding (solo visión)\n",
    "    \"\"\"\n",
    "    B, T, C, H, W = pixel_values.shape\n",
    "\n",
    "    # XCLIP vision_model espera (N, C, H, W) -> procesamos por frame\n",
    "    flat = pixel_values.reshape(B * T, C, H, W).contiguous()\n",
    "\n",
    "    vision_out = encoder.vision_model(pixel_values=flat)\n",
    "\n",
    "    # pooler_output suele estar disponible; fallback a tuple index si aplica\n",
    "    if isinstance(vision_out, (tuple, list)):\n",
    "        frame_pooled = vision_out[1]\n",
    "    else:\n",
    "        frame_pooled = vision_out.pooler_output\n",
    "\n",
    "    # Proyección visual a D\n",
    "    frame_embeds = encoder.visual_projection(frame_pooled)  # (B*T, D)\n",
    "\n",
    "    # Agregar temporalmente por promedio (simple y consistente)\n",
    "    frame_embeds = frame_embeds.view(B, T, -1)             # (B, T, D)\n",
    "    video_embed = frame_embeds.mean(dim=1)                 # (B, D)\n",
    "    return video_embed\n",
    "\n",
    "@torch.no_grad()\n",
    "def measure_xclip_latency(\n",
    "    encoder: XCLIPModel,\n",
    "    T: int,\n",
    "    img_size: int,\n",
    "    device: str,\n",
    "    batch_size: int = 8,\n",
    "    n_batches: int = 200,\n",
    "    warmup: int = 10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Mide latencia del forward del encoder usando input dummy.\n",
    "    Retorna:\n",
    "      - time_per_batch_s\n",
    "      - time_per_clip_s\n",
    "      - time_per_frame_s\n",
    "      - fps_effective\n",
    "    \"\"\"\n",
    "    dummy = torch.randn(batch_size, T, 3, img_size, img_size, device=device)\n",
    "\n",
    "    # warmup\n",
    "    for _ in range(warmup):\n",
    "        _ = xclip_video_embeds_unimodal(encoder, dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    start = time.time()\n",
    "    for _ in range(n_batches):\n",
    "        _ = xclip_video_embeds_unimodal(encoder, dummy)\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    elapsed = time.time() - start\n",
    "\n",
    "    time_per_batch_s = elapsed / n_batches\n",
    "    time_per_clip_s  = time_per_batch_s / batch_size\n",
    "    time_per_frame_s = time_per_clip_s / T\n",
    "    fps_effective    = 1.0 / time_per_frame_s\n",
    "\n",
    "    return {\n",
    "        \"batches_measured\": int(n_batches),\n",
    "        \"batch_size\": int(batch_size),\n",
    "        \"T\": int(T),\n",
    "        \"img_size\": int(img_size),\n",
    "        \"time_per_batch_s\": float(time_per_batch_s),\n",
    "        \"time_per_clip_s\": float(time_per_clip_s),\n",
    "        \"time_per_frame_s\": float(time_per_frame_s),\n",
    "        \"fps_effective\": float(fps_effective),\n",
    "    }\n",
    "\n",
    "# 3) Ejecutar medición\n",
    "op = measure_xclip_latency(\n",
    "    encoder=encoder,\n",
    "    T=T,\n",
    "    img_size=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    batch_size=8,   # ajusta si te falta VRAM\n",
    "    n_batches=200,\n",
    "    warmup=10,\n",
    ")\n",
    "\n",
    "# 4) Variables que usarán tus siguientes pasos (igual que en TimeSformer)\n",
    "time_per_clip  = op[\"time_per_clip_s\"]\n",
    "time_per_frame = op[\"time_per_frame_s\"]\n",
    "fps_effective  = op[\"fps_effective\"]\n",
    "\n",
    "print(\"\\nBatches medidos:\", op[\"batches_measured\"])\n",
    "print(\"Batch size:\", op[\"batch_size\"])\n",
    "print(f\"Tiempo promedio por batch: {op['time_per_batch_s']:.4f} s\")\n",
    "print(f\"Latencia por clip: {time_per_clip*1000:.2f} ms/clip\")\n",
    "print(f\"Tiempo por frame: {time_per_frame*1000:.2f} ms/frame\")\n",
    "print(f\"FPS efectivo: {fps_effective:.2f} fps\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f713a841-343a-4c67-8c9b-045fd7ad4386",
   "metadata": {},
   "source": [
    "## Paso 6 — Time-To-Alert (TTA) estimado\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima un **time-to-alert** aproximado como:\n",
    "- duración temporal de la ventana (clip) = `T / fps_video`\n",
    "- + latencia computacional (ms/clip)\n",
    "\n",
    "### Resultado esperado\n",
    "- Duración ventana\n",
    "- Latencia computacional\n",
    "- TTA estimado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf85616f-cb20-4794-b0a4-041b8d6b73e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 6: Time-To-Alert (TTA) ===\n",
      "FPS video asumido: 30\n",
      "Duración ventana (clip): 0.267 s\n",
      "Latencia computacional: 0.009 s\n",
      "Time-To-Alert estimado: 0.275 s\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 6 — Time-To-Alert (TTA) estimado\n",
    "# =========================\n",
    "# Requiere: T, time_per_clip (calculado en Paso 5)\n",
    "video_fps = 30  # ajusta si tu fuente es distinta\n",
    "\n",
    "latencia_clip_ms = time_per_clip * 1000.0\n",
    "duracion_clip_s = T / video_fps\n",
    "tta_s = duracion_clip_s + (latencia_clip_ms / 1000.0)\n",
    "\n",
    "print(\"\\n=== Paso 6: Time-To-Alert (TTA) ===\")\n",
    "print(f\"FPS video asumido: {video_fps}\")\n",
    "print(f\"Duración ventana (clip): {duracion_clip_s:.3f} s\")\n",
    "print(f\"Latencia computacional: {latencia_clip_ms/1000:.3f} s\")\n",
    "print(f\"Time-To-Alert estimado: {tta_s:.3f} s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33515a13-2293-400a-9613-f7e5b9bba057",
   "metadata": {},
   "source": [
    "## Paso 7 — Complejidad computacional (FLOPs y parámetros)\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se estima:\n",
    "- GFLOPs del encoder\n",
    "- número de parámetros\n",
    "\n",
    "Usando `thop` sobre un tensor dummy con forma compatible.\n",
    "\n",
    "### Resultado esperado\n",
    "- GFLOPs\n",
    "- Params (millones)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0f830bd-dd66-4630-8de5-1761625922fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Paso 7: Complejidad Computacional (XCLIP Video Unimodal) ===\n",
      "FLOPs: 35.44 GFLOPs\n",
      "Parámetros: 123.26 M\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 7 — Complejidad computacional (GFLOPs y parámetros) (VideoCLIP / XCLIP unimodal video)\n",
    "# =========================\n",
    "from thop import profile\n",
    "import torch\n",
    "\n",
    "encoder.eval()\n",
    "\n",
    "dummy = torch.randn(1, T, 3, IMG_SIZE, IMG_SIZE).to(DEVICE)\n",
    "\n",
    "# Wrapper: THOP llama forward(x) -> devolvemos tensor (B, D)\n",
    "class XCLIPVideoWrapper(torch.nn.Module):\n",
    "    def __init__(self, enc):\n",
    "        super().__init__()\n",
    "        self.enc = enc\n",
    "    def forward(self, x):\n",
    "        # x: (B, T, C, H, W)\n",
    "        return xclip_video_embeds_unimodal(self.enc, x)  # (B, D)\n",
    "\n",
    "wrapped = XCLIPVideoWrapper(encoder).to(DEVICE)\n",
    "flops, params = profile(wrapped, inputs=(dummy,), verbose=False)\n",
    "\n",
    "print(\"\\n=== Paso 7: Complejidad Computacional (XCLIP Video Unimodal) ===\")\n",
    "print(f\"FLOPs: {flops/1e9:.2f} GFLOPs\")\n",
    "print(f\"Parámetros: {params/1e6:.2f} M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c48383-a294-4ce4-9354-75f484ea1b53",
   "metadata": {},
   "source": [
    "## Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "\n",
    "### ¿Qué se hace en esta celda?\n",
    "Se arma una tabla única para reportar en tesis, combinando:\n",
    "- desempeño (Test)\n",
    "- métricas operativas (ms/frame, FPS, TTA)\n",
    "- costo computacional (GFLOPs)\n",
    "\n",
    "### Resultado esperado\n",
    "- DataFrame `final_table`\n",
    "- CSV exportado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15d9d5cc-3b83-423a-9b93-f3ee633b3824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Modelo</th>\n",
       "      <th>AUC (Test)</th>\n",
       "      <th>F1 (Test)</th>\n",
       "      <th>Recall (Test)</th>\n",
       "      <th>FAR (Test)</th>\n",
       "      <th>Accuracy (Test)</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>ms/frame</th>\n",
       "      <th>FPS</th>\n",
       "      <th>TTA (s)</th>\n",
       "      <th>GFLOPs</th>\n",
       "      <th>Params (M)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/xclip-base-patch32 + MLP</td>\n",
       "      <td>0.4832</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.1175</td>\n",
       "      <td>0.4386</td>\n",
       "      <td>8067</td>\n",
       "      <td>1074</td>\n",
       "      <td>9612</td>\n",
       "      <td>283</td>\n",
       "      <td>1.07</td>\n",
       "      <td>936.57</td>\n",
       "      <td>0.275</td>\n",
       "      <td>35.44</td>\n",
       "      <td>123.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Modelo  AUC (Test)  F1 (Test)  Recall (Test)  \\\n",
       "0  microsoft/xclip-base-patch32 + MLP      0.4832     0.0503         0.0286   \n",
       "\n",
       "   FAR (Test)  Accuracy (Test)    TN    FP    FN   TP  ms/frame     FPS  \\\n",
       "0      0.1175           0.4386  8067  1074  9612  283      1.07  936.57   \n",
       "\n",
       "   TTA (s)  GFLOPs  Params (M)  \n",
       "0    0.275   35.44      123.26  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: processed/final_report_videoclip_full.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Paso 8 — Tabla final integrada (desempeño + operativas) y exportación\n",
    "# (VideoCLIP / XCLIP + MLP)\n",
    "# =========================\n",
    "# Requiere:\n",
    "# test_metrics, acc_test, tn, fp, fn, tp,\n",
    "# flops, params, tta_s,\n",
    "# time_per_frame, fps_effective,\n",
    "# manifest, Path\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "PROCESSED = Path(\"processed\")\n",
    "\n",
    "MODEL_NAME = manifest.get(\"model\", \"VideoCLIP\")\n",
    "MODEL_LABEL = f\"{MODEL_NAME} + MLP\"\n",
    "\n",
    "final_table = pd.DataFrame({\n",
    "    \"Modelo\": [MODEL_LABEL],\n",
    "\n",
    "    # =====================\n",
    "    # MÉTRICAS DE DESEMPEÑO\n",
    "    # =====================\n",
    "    \"AUC (Test)\": [round(test_metrics[\"auc\"], 4)],\n",
    "    \"F1 (Test)\": [round(test_metrics[\"f1\"], 4)],\n",
    "    \"Recall (Test)\": [round(test_metrics[\"recall\"], 4)],\n",
    "    \"FAR (Test)\": [round(test_metrics[\"far\"], 4)],\n",
    "    \"Accuracy (Test)\": [round(float(acc_test), 4)],\n",
    "\n",
    "    \"TN\": [int(tn)],\n",
    "    \"FP\": [int(fp)],\n",
    "    \"FN\": [int(fn)],\n",
    "    \"TP\": [int(tp)],\n",
    "\n",
    "    # =====================\n",
    "    # MÉTRICAS OPERATIVAS\n",
    "    # =====================\n",
    "    \"ms/frame\": [round(time_per_frame * 1000.0, 2)],\n",
    "    \"FPS\": [round(float(fps_effective), 2)],\n",
    "    \"TTA (s)\": [round(float(tta_s), 3)],\n",
    "\n",
    "    \"GFLOPs\": [round(float(flops / 1e9), 2)],\n",
    "    \"Params (M)\": [round(float(params / 1e6), 2)],\n",
    "})\n",
    "\n",
    "display(final_table)\n",
    "\n",
    "# Export específico para VideoCLIP\n",
    "out_csv = PROCESSED / \"final_report_videoclip_full.csv\"\n",
    "final_table.to_csv(out_csv, index=False)\n",
    "\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e2aa0-86fb-49d3-85f3-501c4ad90558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tesis)",
   "language": "python",
   "name": "tesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
